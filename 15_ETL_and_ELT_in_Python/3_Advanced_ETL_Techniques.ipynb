{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3978bb09-3a11-403f-abdd-9787e2139d98",
   "metadata": {},
   "source": [
    "## Extracting non-tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ddc9c-ed0d-46e7-902f-d0ccb93f8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a JSON file in the format above\n",
    "raw_stock_data = pd.read_json(\"raw_stock_data.json\", orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce69a4-33fb-4fe9-a69b-7d58cd94d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"raw_stock_data.json\", \"r\") as file:\n",
    "    \n",
    "    # Load the file into a dictionary    \n",
    "    raw_stock_data = json.load(file)\n",
    "    \n",
    "# Confirm the type of the raw_stock_data variable\n",
    "print(type(raw_stock_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006adf1-9df5-4a1b-b855-dd50ff59ad0c",
   "metadata": {},
   "source": [
    "### Ingesting JSON data with pandas\n",
    "When developing a data pipeline, you may have to work with non-tabular data and data sources, such as APIs or JSON files. In this exercise, we'll practice extracting data from a JSON file using pandas.\n",
    "\n",
    "pandas has been imported as pd, and the JSON file you'll ingest is stored at the path \"testing_scores.json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7cb49-e31f-4d2f-ae0a-61cc2a6b806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_path):\n",
    "  # Read the JSON file into a DataFrame\n",
    "  return pd.read_json(file_path, orient=\"records\")\n",
    "\n",
    "# Call the extract function with the appropriate path, assign to raw_testing_scores\n",
    "raw_testing_scores = extract('testing_scores.json')\n",
    "\n",
    "# Output the head of the DataFrame\n",
    "print(raw_testing_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b3aca-86d1-4568-951e-af5d05dc978b",
   "metadata": {},
   "source": [
    "### Reading JSON data into memory\n",
    "When data is stored in JSON format, it's not always easy to load into a DataFrame. This is the case for the \"nested_testing_scores.json\" file. Here, the data will have to be manually manipulated before it can be stored in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a5508-a32b-4239-86b4-c8dae6a0baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_path):\n",
    "  \t# Read the JSON file into a DataFrame, orient by index\n",
    "\treturn pd.read_json(file_path, orient=\"index\")\n",
    "\n",
    "# Call the extract function, pass in the desired file_path\n",
    "raw_testing_scores = extract(\"nested_scores.json\")\n",
    "print(raw_testing_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7e526-6e1b-4428-8766-600ea8df87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the json library\n",
    "import json\n",
    "\n",
    "def extract(file_path):\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        # Load the data from the JSON file\n",
    "        raw_data = json.load(json_file)\n",
    "    return raw_data\n",
    "\n",
    "raw_testing_scores = extract(\"nested_scores.json\")\n",
    "\n",
    "# Print the raw_testing_scores\n",
    "print(raw_testing_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec51dd6-867b-4ccf-9298-efcc41eb42b0",
   "metadata": {},
   "source": [
    "## Transforming non-tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d1efc-3359-4bf9-a6f6-94546ffa1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over keys\n",
    "for key in raw_data.keys():   # Creates a list of keys stored in a dictionary\n",
    "    \n",
    "# Loop over values\n",
    "for value in raw_data.values(): # Creates a list of values stored in adictionary\n",
    "    \n",
    "# Loop over keys and values\n",
    "for key, value in raw_data.items():  # Generates a list of tuples, made up of thekey-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4963b5-01e4-40a4-a8de-874acdb6aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data from dictionary using .get()\n",
    "volume = entry.get(\"volume\")\n",
    "ticker = entry.get(\"ticker\", \"DCMP\")\n",
    "# Call .get() twice to return the nested \"open\" value\n",
    "open_price = entry.get(\"price\").get(\"open\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3aec8c-2fec-443b-8444-cac88ce3890a",
   "metadata": {},
   "source": [
    "### Iterating over dictionaries\n",
    "Once JSON data is loaded into a dictionary, you can leverage Python's built-in tools to iterate over its keys and values.\n",
    "\n",
    "The \"nested_school_scores.json\" file has been read into a dictionary stored in the raw_testing_scores variable, which takes the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fc51f-7bf3-414d-887c-4b3925bca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_testing_scores_keys = []\n",
    "\n",
    "# Iterate through the keys of the raw_testing_scores dictionary\n",
    "for school_id in raw_testing_scores.keys():\n",
    "  \t# Append each key to the raw_testing_scores_keys list\n",
    "\traw_testing_scores_keys.append(school_id)\n",
    "    \n",
    "print(raw_testing_scores_keys[0:3]) \n",
    "\n",
    "\n",
    "raw_testing_scores_values = []\n",
    "\n",
    "# Iterate through the values of the raw_testing_scores dictionary\n",
    "for school_info in raw_testing_scores.values():\n",
    "\traw_testing_scores_values.append(school_info)\n",
    "    \n",
    "print(raw_testing_scores_values[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be1195-459b-4223-a636-a6047165a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_testing_scores_keys = []\n",
    "raw_testing_scores_values = []\n",
    "\n",
    "# Iterate through the values of the raw_testing_scores dictionary\n",
    "for school_id, school_info in raw_testing_scores.items():\n",
    "\traw_testing_scores_keys.append(school_id)\n",
    "\traw_testing_scores_values.append(school_info)\n",
    "\n",
    "print(raw_testing_scores_keys[0:3])\n",
    "print(raw_testing_scores_values[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bc026-8112-48d4-a1c5-57e9bc0ecc6d",
   "metadata": {},
   "source": [
    "### Parsing data from dictionaries\n",
    "When JSON data is loaded into memory, the resulting dictionary can be complicated. Key-value pairs may contain another dictionary, such are called nested dictionaries. These nested dictionaries are frequently encountered when dealing with APIs or other JSON data. In this exercise, you will practice extracting data from nested dictionaries and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e23e6-9d30-47e1-81ac-b9c8b4b35bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the street_address from the dictionary\n",
    "street_address = school.get(\"street_address\")\n",
    "\n",
    "# Parse the scores dictionary\n",
    "scores = school.get(\"scores\")\n",
    "\n",
    "# Try to parse the math, reading and writing values from scores\n",
    "math_score = scores.get(\"math\", 0)\n",
    "reading_score = scores.get('reading', 0)\n",
    "writing_score = scores.get('writing', 0)\n",
    "\n",
    "print(f\"Street Address: {street_address}\")\n",
    "print(f\"Math: {math_score}, Reading: {reading_score}, Writing: {writing_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95840f7-cc34-43b3-a62e-67ac3c05b298",
   "metadata": {},
   "source": [
    "### Transforming JSON data\n",
    "Chances are, when reading data from JSON format into a dictionary, you'll probably have to apply some level of manual transformation to the data before it can be stored in a DataFrame. This is common when working with nested dictionaries, which you'll have the opportunity to explore in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50132d-b2df-4147-a418-a28333c978f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_testing_scores = []\n",
    "\n",
    "# Loop through each of the dictionary key-value pairs\n",
    "for school_id, school_info in raw_testing_scores.items():\n",
    "\tnormalized_testing_scores.append([\n",
    "    \tschool_id,\n",
    "    \tschool_info.get(\"street_address\"),  # Pull the \"street_address\"\n",
    "    \tschool_info.get(\"city\"),\n",
    "    \tschool_info.get(\"scores\").get(\"math\", 0),\n",
    "    \tschool_info.get(\"scores\").get(\"reading\", 0),\n",
    "    \tschool_info.get(\"scores\").get(\"writing\", 0),\n",
    "    ])\n",
    "\n",
    "print(normalized_testing_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d11018-37cb-457a-a852-1b95c69cd42c",
   "metadata": {},
   "source": [
    "### Transforming and cleaning DataFrames\n",
    "Once data has been curated into a cleaned Python data structure, such as a list of lists, it's easy to convert this into a pandas DataFrame. You'll practice doing just this with the data that was curated in the last exercise.\n",
    "\n",
    "Per usual, pandas has been imported as pd, and the normalized_testing_scores variable stores the list of each schools testing data, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747a6ed-04ae-49ee-a70c-75059dd99b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the normalized_testing_scores list\n",
    "normalized_data = pd.DataFrame(normalized_testing_scores)\n",
    "\n",
    "# Set the column names\n",
    "normalized_data.columns = [\"school_id\", \"street_address\", \"city\", \"avg_score_math\", \"avg_score_reading\", \"avg_score_writing\"]\n",
    "\n",
    "normalized_data = normalized_data.set_index(\"school_id\")\n",
    "print(normalized_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c3d0b-3a36-4a7d-8054-ce245771276d",
   "metadata": {},
   "source": [
    "## Advanced data transformation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552ca34-522d-44c0-af1c-9a94abe97ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_change(row): \n",
    "    change = row[\"close\"] - row[\"open\"]\n",
    "    if change > 0:\n",
    "        return \"Increase\" \n",
    "    else:\n",
    "        return \"Decrease\"\n",
    "        \n",
    "# Apply transformation to DataFrame \n",
    "raw_stock_data[\"change\"] = raw_stock_data.apply(classify_change, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d175b-f69c-4872-8659-bca9808f3095",
   "metadata": {},
   "source": [
    "### Filling missing values with pandas\n",
    "When building data pipelines, it's inevitable that you'll stumble upon missing data. In some cases, you may want to remove these records from the dataset. But in others, you'll need to impute values for the missing information. In this exercise, you'll practice using pandas to impute missing test scores.\n",
    "\n",
    "Data from the file \"testing_scores.json\" has been read into a DataFrame, and is stored in the variable raw_testing_scores. In addition to this, pandas has been loaded as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b0913-0cce-42df-b8be-d3b8525a9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the `raw_testing_scores` DataFrame\n",
    "print(raw_testing_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e5561-86c6-409a-b54d-6597ecb250b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with the average from that column\n",
    "raw_testing_scores[\"math_score\"] = raw_testing_scores[\"math_score\"].fillna(raw_testing_scores[\"math_score\"].mean())\n",
    "\n",
    "# Print the head of the raw_testing_scores DataFrame\n",
    "print(raw_testing_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae53389-5920-4f0a-ba41-82d1ae9f201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data):\n",
    "\traw_data.fillna(\n",
    "    \tvalue={\n",
    "\t\t\t# Fill NaN values with column mean\n",
    "\t\t\t\"math_score\": raw_data[\"math_score\"].mean(),\n",
    "\t\t\t\"reading_score\": raw_data['reading_score'].mean(),\n",
    "\t\t\t\"writing_score\": raw_data['writing_score'].mean()\n",
    "\t\t}, inplace=True\n",
    "\t)\n",
    "\treturn raw_data\n",
    "\n",
    "clean_testing_scores = transform(raw_testing_scores)\n",
    "\n",
    "# Print the head of the clean_testing_scores DataFrame\n",
    "print(clean_testing_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de056613-bb21-45f4-aef0-a3ef401f91cf",
   "metadata": {},
   "source": [
    "### Grouping data with pandas\n",
    "The output of a data pipeline is typically a \"modeled\" dataset. This dataset provides data consumers easy access to information, without having to perform much manipulation. Grouping data with pandas helps to build modeled datasets, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a604a8a-90ef-47ef-85b5-38676195c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data):\n",
    "\t# Use .loc[] to only return the needed columns\n",
    "\traw_data = raw_data.loc[:, [\"city\",\"math_score\",\"reading_score\",\"writing_score\"]]\n",
    "\t\n",
    "    # Group the data by city, return the grouped DataFrame\n",
    "\tgrouped_data = raw_data.groupby(by=[\"city\"], axis=0).mean()\n",
    "\treturn grouped_data\n",
    "\n",
    "# Transform the data, print the head of the DataFrame\n",
    "grouped_testing_scores = transform(raw_testing_scores)\n",
    "print(grouped_testing_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfe5db-83f1-40ed-a547-daa7161e20f5",
   "metadata": {},
   "source": [
    "### Applying advanced transformations to DataFrames\n",
    "pandas has a plethora of built-in transformation tools, but sometimes, more advanced logic needs to be used in a transformation. The apply function lets you apply a user-defined function to a row or column of a DataFrame, opening the door for advanced transformation and feature generation.\n",
    "\n",
    "The find_street_name() function parses the street name from the \"street_address\", dropping the street number from the string. This function has been loaded into memory, and is ready to be applied to the raw_testing_scores DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d95950-5c5b-4f85-ae35-e4bfc5cc896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data):\n",
    "\t# Use the apply function to extract the street_name from the street_address\n",
    "    raw_data[\"street_name\"] = raw_data.apply(\n",
    "   \t\t# Pass the correct function to the apply method\n",
    "        find_street_name,\n",
    "        axis=1\n",
    "    )\n",
    "    return raw_data\n",
    "\n",
    "# Transform the raw_testing_scores DataFrame\n",
    "cleaned_testing_scores = transform(raw_testing_scores)\n",
    "\n",
    "# Print the head of the cleaned_testing_scores DataFrame\n",
    "print(cleaned_testing_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7fb1d-086f-40b5-9e9c-dd293e783461",
   "metadata": {},
   "source": [
    "## Loading data to a SQL database with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e5507-a002-48e2-a243-aa643fd07205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .to_sql() method to persist data to SQL\n",
    "clean_stock_data.to_sql(\n",
    "    name=\"filtered_stock_data\",\n",
    "    con=db_engine,   \n",
    "    if_exists=\"append\",  # or 'replace'\n",
    "    index=True,  \n",
    "    index_label=\"timestamps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676de670-e23c-4b50-96a3-439e11cc8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data written to SQL table\n",
    "to_validate = pd.read_sql(\"SELECT * FROM cleaned_stock_data\", db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d28ca-70f2-4322-b056-6bc487a68766",
   "metadata": {},
   "source": [
    "### Loading data to a Postgres database\n",
    "After data has been extracted from a source system and transformed to align with analytics or reporting use cases, it's time to load the data to a final storage medium. Storing cleaned data in a SQL database makes it simple for data consumers to access and run queries against. In this example, you'll practice loading cleaned data to a Postgres database.\n",
    "\n",
    "sqlalchemy has been imported, and pandas is available as pd. The first few rows of the cleaned_testing_scores DataFrame are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddab54-9bbb-400d-a362-5626f8e740a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the connection string, create the connection object to the schools database\n",
    "db_engine = sqlalchemy.create_engine(\"postgresql+psycopg2://repl:password@localhost:5432/schools\")\n",
    "\n",
    "# Write the DataFrame to the scores table\n",
    "cleaned_testing_scores.to_sql(\n",
    "\tname=\"scores\",\n",
    "\tcon=db_engine,\n",
    "\tindex=False,\n",
    "\tif_exists=\"replace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31445d-c0a0-4aab-be83-aa909f2451ae",
   "metadata": {},
   "source": [
    "### Validating data loaded to a Postgres Database\n",
    "In this exercise, you'll finally get to build a data pipeline from end-to-end. This pipeline will extract school testing scores from a JSON file and transform the data to drop rows with missing scores. In addition to this, each will be ranked by the city they are located in, based on their total scores. Finally, the transformed dataset will be stored in a Postgres database.\n",
    "\n",
    "To give you a head start, the extract() and transform() functions have been built and used as shown below. In addition to this, pandas has been imported as pd. Best of luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061b873-c405-43e3-ba69-fe62effa2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(clean_data, con_engine):\n",
    "\t# Store the data in the schools database\n",
    "    clean_data.to_sql(\n",
    "    \tname=\"scores_by_city\",\n",
    "\t\tcon=con_engine,\n",
    "\t\tif_exists=\"replace\",  # Make sure to replace existing data\n",
    "\t\tindex=True,\n",
    "\t\tindex_label=\"school_id\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f05a2-e967-44f7-95c4-eabc245b564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(clean_data, con_engine):\n",
    "    clean_data.to_sql(name=\"scores_by_city\", con=con_engine, if_exists=\"replace\", index=True, index_label=\"school_id\")\n",
    "    \n",
    "# Call the load function, passing in the cleaned DataFrame\n",
    "load(cleaned_testing_scores, db_engine)\n",
    "\n",
    "# Call query the data in the scores_by_city table, check the head of the DataFrame\n",
    "to_validate = pd.read_sql(\"SELECT * FROM scores_by_city\", con=db_engine)\n",
    "print(to_validate.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e897c-6349-44a2-811f-b47498616d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
